name: ML Pipeline CI

on:
  # push:
  #   branches: [ main, master  ]
  pull_request:
    branches: [ main, master ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest great_expectations pandas scikit-learn flake8 black mypy pytest-cov
        if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
        
    - name: Lint with flake8
      run: |
        flake8 day5/演習3 --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 day5/演習3 --count --exit-zero --max-complexity=10 --max-line-length=88 --statistics
        
    - name: Format check with black
      run: |
        black --check day5/演習3
        
    - name: Run data tests
      run: |
        pytest day5/演習3/tests/test_data.py -v
        
    - name: Run model tests
      run: |
        pytest day5/演習3/tests/test_model.py -v
  

    - name: Prepare for inference speed test # 宿題用追加分
      run: |
        # もし推論用スクリプトが特定のデータ配置を期待する場合、ここで準備します。
        # 例: cp day5/演習3/data/processed/titanic_processed.csv ./titanic_for_inference.csv
        # 例: cp day5/演習3/models/your_model.pkl ./model_for_inference.pkl
        echo "Preparation step if needed"

    - name: Measure inference speed
      run: |
        # ここで推論スピードを測定するPythonスクリプトを実行します。
        # スクリプトはリポジトリ内に事前に作成しておきます。
        # スクリプト内で時間測定と結果の出力を行います。
        echo "Running inference speed measurement script..."
        python C:\git-fed\lecture-ai-engineering\measure_titanic_inference.py # スクリプトのパスを正しく指定してください

    # (オプション) 測定結果をアーティファクトとして保存
    - name: Upload inference speed result
      uses: actions/upload-artifact@v4
      with:
        name: inference-speed-report
        path: # スクリプトが出力した結果ファイルやログファイルのパスを指定
          # 例: ./inference_speed_result.txt
          # 例: ./inference_reports/
